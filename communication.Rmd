---
title             : "Psychometric Validation of the Bangla Communication Scale in a Bagladeshi Adolescents Sample"
shorttitle        : "Bangla Communication Scale"

author: 
  - name          : "Nusrat Jahan"
    affiliation   : "1"
    corresponding : no    # Define only one corresponding author
    role:         
      - Conceptualization
      - Project Management
      - Data Curation
      - Writing - Original Draft Preparation
  - name          : "Mushfiqul Anwar Siraji"
    affiliation   : "2"
    corresponding : no   # Define only one corresponding author
    address       : "Monash University Malaysia,Jalan Lagoon Selatan, 47500 Bandar Sunway,Selangor Darul Ehsan, Malaysia."
    email         : "mushfiqul.anwarsiraji@moansh.edu"
    role:
      - Conceptualization
      - Project Management
      - Formal Analysis & Data Visualization
      - Writing - Original Draft Preparation; Review & Editing

  - name          : "Zinnatul Borak"
    affiliation   : "1"
    corresponding : yes   # Define only one corresponding author
    address       : "Department of Educational and Counselling Psychology,University of Dhaka,Dhaka 1000"
    email         : "institutional email of Bonhee mam"
    role:
      - Conceptualization
      - Writing - Review & Editing

     

affiliation:
  - id            : "1"
    institution   : "Department of Educational and Counselling Psychology,University of Dhaka"
  - id            : "2"
    institution   : "Monash University, Department of Psychology, Jeffrey Cheah School of Medicine and Health Sciences, Malaysia"
 

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib", "references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    keep_tex: false
    latex_engine: xelatex
    includes:
      in_header: header.tex

mainfont: Arial
---

```{r setup, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F, dpi=600, fig.width = 6,
 fig.asp = 0.8,out.width = "80%", dev=c('png','postscript'))
#options(knitr.duplicate.label = "allow")
set.seed(123)
par(family = "Arial")
```

```{r pacman, eval=FALSE, include=FALSE}
#You need to run this chunk 1X in your system 
#install.packages("pacman")#Run this if you don't have pacman installed.
pacman::p_load(MOTE, tidyverse, psych, lavaan,kableExtra,gt,gtsummary, mirt,likert,kutils,semPlot,semTable,semTools,ggcorrplot,dlookr,qgraph,paran,EFA.MRFA,VIM,DiagrammeR,DiagrammeRsvg,ggplot2,cowplot,rsvg,questionr,magick, simsem,readxl, stringr,RColorBrewer,WrightMap, foreign,DT,SimDesign)
library(papaja)
pacman::p_install_gh("jthomasmock/gtExtras")
pacman::p_install_gh("crsh/papaja")
pacman::p_install_gh("masiraji/tabledown")
pacman::p_install_gh("crsh/citr")

papaja::r_refs("references.bib")
#if you dont have LaTeX installed run the following lines
#install.packages("tinytex")
#tinytex::install_tinytex()
renv::snapshot()
```

```{r library,include=FALSE}
#This chunk holds code for calling the required packages

library(papaja) # devtools::install_github("crsh/papaja")
library(lavaan)
library(semPlot) #devtools::install_github('SachaEpskamp/semPlot',  dependencies = T)
library(semTools)
library(MOTE)
library(car)#reversecoding 
library(psych)
library(dlookr)
library(plyr)
library(tidyverse)
library(qgraph)
library(kableExtra)
library(paran) # Parallel analysis
library(EFA.MRFA) # Hull method
library(DiagrammeR) #devtools::install_github('rich-iannone/DiagrammeR')
library(DiagrammeRsvg) #For DiagrammeR
library(rsvg) #For DiagrammeR
library(ggcorrplot)
library(semTable)
library(magick)
library(mirt)
library(gtsummary)
library(gt)
library(gtExtras)
library(likert)
library(VIM) #Missing data
library(kutils)
library(simsem)
library(tabledown)
library(readxl)
library(koRpus)# stable release
library(koRpus.lang.en)
library(reshape)
library(ggsci)
renv::snapshot()
r_refs("references.bib")
```

---
nocite: |
  `r papaja::cite_r("references.bib")`
  
---


Communication is a complex behaviour of exchanging information among individuals [@tanner2006advanced]. Communication plays a central role among adolescents in developing self-identity, social relationships and creates the foundation of collective social activity [@haslett1989children; @conti2008emotional; @spencer2013language]. Inadequate communication skill may cause poor peer relationship resulting long-term socio-emotional difficulties including social anxiety, stress, low self-esteem and poor academic performance [@brinton2004social; @reed2020relative]. 


Often adults picture adolescents having inadequate and inept communication skills [@thurlow2003teenagers;@stern2005self]. Media representation of adolescents often includes "storm-and stress", self absorbed and disengaged type behaviours [@porteous1980adolescents;@stern2005self]. As such adolescents are often labelled as "lazy" and "disrespectful" by the adults [@public1999kids]. On the contrary adolescents are highly engaged in work, community services and extracurricular activities and also more aspiring to earn an college degrees [@debard2004millennials; @schneider1999ambitious]. Such a discrepancy between the reality of adolescent's image and adult's perception of the adolescents might be attributed to the mismatch of communication skills. The communication pattern of adolescents might not necessarily same as the adults. In addition to face to face communication, adolescents are vastly exposed to different virtual communication platforms. This may cause them to face more complex social challenges than the adults [@thurlow2003teenagers]. "Communication capital" expresses the potential of civic-engagement that incorporates developing social relationships and influences collective social activity. The more communication capital an individual has the easier the instances of civic engagement become. 

Understanding the adolescents' communication skill  vital as it is considered as the "key skill" in the education [@thurlow2001talkin] and employment market [@olszewski2017training]. In the western society, adolescents are now facing high unemployment [@lindsay2014employers]. Lack of adequate communication skill is one of the root causes of this high unemployment [@lindsay2014employers]. Similarly, lack of proper communication skill often promotes the propensity of anti-social behaviours and risk of exclusion from schools [@clegg2009language; @conti2004social]. 


To promote better understanding of subject contents assessing the communication skill among adolescents is highly required. For this purpose "Communication Skill" sub-skill set [@barkman2002four]  was developed in 2002 as a part of The  National  On-line  Youth  Life  Skills  Evaluation System [@mincemoyer2005measuring] and since then it has been extensively used [@fitzpatrick2005life].


# Data collection

```{r data, include=F}
# data <- readr::read_csv("rebpsconference/data.csv")
# readr::write_rds(data, "communication_data_n_768.rds")
data <- readr::read_rds("communication_data_n_622.rds")

participangts.age.over.19 <- nrow(data[data$Age>18, ])

overaged.row <- which(data$Age>18, arr.ind=TRUE)

data[265,4] <- 18
data[285,4] <- 18
data[291,4] <- 18
data[300,4] <- 18
data[308,4] <- 18
data[313,4] <- 18
data[325,4] <- 18
data[371,4] <- 18

efa.data.full <- subset(data, Sample == "EFA"| Sample=="Testretest")
cfa.data.full <- subset(data, Sample == "CFA"| Sample=="Validity")
validity.data.full <- subset(data, Sample == "Validity")


sem.data <- data[,c(2,6:66)]
efa.data <- subset(sem.data , Sample == "EFA"| Sample=="Testretest")
efa.data <- efa.data[,c(2:24)]
efa.data <- na.omit(efa.data)

cfa.data.all<- subset(sem.data , Sample == "CFA"| Sample=="Validity")

cfa.data <- cfa.data.all[,c(2:24)]
cfa.data <- na.omit(cfa.data)

validity.data <- subset(sem.data , Sample == "Validity")
validity.data <-na.omit(validity.data)
# das21.data.full <- subset(data, Sample =="DAS21")

irt.data <- sem.data[,2:24]

testretest_data <- subset(data, Sample=="Testretest")
test <- testretest_data[, c(6:28)]
retest <- testretest_data[, c(67:89)]

all.item.test <- test %>% 
  rowwise() %>% 
  mutate(test_total=sum(across(contains("CS")), na.rm = T))

all.item.retest <- retest %>% 
  rowwise() %>% 
  mutate(retest_total=sum(across(contains("CSA")), na.rm = T))

all.item.icc <- as.data.frame(cbind(all.item.test$test_total, all.item.retest$retest_total))

# 

# cor(all.item.test$test_total,all.item.retest$retest_total)

```

The project received institutional ethics clearance from Department of Educational and Counselling Psychology (Project ID: DECP/07/06). Prior to data collection required authorization from school's authority and assent from the participating were obtained. Necessary explanations were given in oral and written forms.It  was also mentioned in the explanatory statement that their participation was voluntary and that they could withdraw from participation any time without being penalized.  Data collection was commenced between November 2021 to January 2022. The data collection took place in the classroom where students were at first briefed about 'communication skill'. Next, they filled up their socio-demographics information and responded to Bangla Communication Scale. All personal information (name, school,class) was codified and encrypted, producing a anonymous database. We at first collected data from `r nrow(efa.data)` participants for our Study-1 and in our Study-2 we collected data from another `r nrow(cfa.data)` participants. Along with Bangla Communication Scale a subset of our Study-2 sample `r nrow(validity.data)` also responded to Bangla Beck Hopelessness Scale[@beck1974measurement]

# Study-1: Translations and Exploratory Factor Analysis

Study-1 had two objectives. First we translated the 23 items of the Communication Scale [@barkman2002four] from English to Bangla. Second, we conducted an Exploratory Factor Analysis (EFA) to identify the latent structure of the scale.


## Methods

### Participants

```{r dsescrptives, include=FALSE}
desc <- efa.data.full[,c(3,4,5)]
## Recoding desc$Sex
desc$Gender <- fct_recode(desc$Gender,
  "Boy" = "male",
  "Girl" = "female"
)
colnames(desc) <- c("Gender", "Age", "Socio Economic Status")

des_tab <- desc %>%
  tbl_summary(
    by = Gender,
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                     all_categorical() ~ "{n} ({p}%)"),
    type = list(Age ~ 'continuous'),
    digits = all_continuous() ~ 2,
    
    missing = "no"
    ) %>% add_overall() %>% bold_labels() %>% 
modify_header(label ~ "**Variable**")  %>%
  modify_caption("Demographic Characteristics")  

as_tibble(des_tab) -> desc_tibble 
as_kable_extra(des_tab, format = "latex",booktabs = T) -> desc_kable #save it as a knitr::kable


des.2 <- desc %>% 
  psych::describeBy("Gender")
female <- as.tibble(des.2$Girl)
male <- as.tibble(des.2$Boy)


desc.test.retest.data <- testretest_data[,c(3,4,5)]

desc.test.retest.data$Gender <- fct_recode(desc.test.retest.data$Gender,
  "Boy" = "male",
  "Girl" = "female")
test.retest.description <- desc.test.retest.data %>% 
  psych::describeBy("Gender")
test.female <- as.tibble(test.retest.description$Girl)
test.male <- as.tibble(test.retest.description$Boy)


test.retest.des_tab <- desc.test.retest.data %>%
  tbl_summary(
    by = Gender,
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                     all_categorical() ~ "{n} ({p}%)"),
    type = list(Age ~ 'continuous'),
    digits = all_continuous() ~ 2,
    
    missing = "no"
    ) %>% add_overall() %>% bold_labels() %>% 
modify_header(label ~ "**Variable**")  %>%
  modify_caption("Demographic Characteristics")  

as_tibble(test.retest.des_tab) -> test.retset.desc_tibble 


```

A cross-sectional survey was used to collect data from a large sample of students of grade 8-12 (n = `r nrow(efa.data)`) from 8 schools following convenience sampling method.There was no missing data.  Participants were recruited following convenience sampling technique. For exploring the initial factor structure the recommended sample size is 250-300 [@comreyFirstCourseFactor1992; @schonbrodtWhatSampleSize2013]. Among `r nrow(efa.data)` participants, `r female[1,2]` were female aged between `r female[2,8]` to `r female[2,9]` years (`r round(female[2,3],2)`±`r round(female[2,4],2)`). `r male[1,2]`  were male with an age range between `r male[2,8]` participants `r male[2,9]` years (`r round(male[2,3],2)`±`r round(male[2,4],2)`). `r desc_tibble [4,2]` participants belonged to middle socio-economic status. `r desc_tibble [3,2]` and `r desc_tibble [5,2]` participants belonged to lower and upper socio-economic status-respectively.

To estimate the test-retest reliability we used intraclass correlation coefficients (ICC) . With 80% power and alpha at 0.05, a minimum sample size of 22 is recommended to detect the ICC value of .50 [@bujang2017simplified]. Considering potential instances of drop-out we randomly chose a subset of `r nrow(testretest_data)` participants from our study-1 sample. They responded to the Bangla communication scale twice, two week apart.  Among these `r nrow(testretest_data)` participants `r test.female[1,2]` were female aged between `r test.female[2,8]` to `r test.female[2,9]` years (`r round(test.female[2,3],2)`±`r round(test.female[2,4],2)`). `r test.male[1,2]`  were male with an age range between `r test.male[2,8]` participants `r test.male[2,9]` years (`r round(test.male[2,3],2)`±`r round(test.male[2,4],2)`). `r  test.retset.desc_tibble [4,2]` participants belonged to middle socio-economic status. `r  test.retset.desc_tibble [3,2]` and `r  test.retset.desc_tibble [5,2]` participants belonged to lower and upper socio-economic status-respectively.

### Materials

#### Communication Scale

Communication Scale [@barkman2002four] is a sub-skill set of The  National  On-line  Youth  Life  Skills  Evaluation System [@mincemoyer2005measuring]. It has 23 items with a 5 Point Likert Type response scale (0=Never, 1=Rarely,  2=Sometimes,  3=Often,  4=Always). The total score range is 0-92 where a higher score would indicate higher communication skills among adolescents (age range 12-18). The internal consistency of the total scale, Cronbach $\alpha$ was .79

#### Bangla Communication Scale
We followed the International Test Commission  guidelines [@bartramITCGuidelinesTranslating2018] while translating the Communication Scale in Bangla. At first two bilingual researchers did the forward translation. These two forward translations were synthesized by the authors. Another four bilingual researchers did the backward translation of the synthesized Bangla Communication Scale. The authors again synthesized the back-translations, compared it with original scale and made necessary amendments.


### Analytic strategies

We used R (version 4.1.0) [@R-base], including several R packages [@R-lavaan; @R-mirt; @R-psych; @R-tabledown], At first we checked for missing values and outliers. To estimate test-retest reliability of the Bangla communication scale we used intraclass correlation coefficients computed based on single-rating, absolute-agreement, 2-way random-effects model. An ICC value higher than .50 is considered adequate [@koo2016guideline]. Our data violated both univariate and multivariate normality. As such we used polychoric correlation matrix as it is more robust towards these violations. For initial item analysis we calculated item-total correlation and estimated internal consistency reliability coefficient ordinal alpha drop statistics. Though Cronbach's alpha is the the most popular reliability coefficient,it has a tendency to deflate the estimates for  Likert type data as the calculation is based on pearson-correlation matrix which requires data with continuous measurement level [@gadermann2012estimating; @zumbo2007ordinal]. Since our data followed Likert types response format for better estimation of reliability we reported ordinal alpha using polychoric-correlation [@zumbo2007ordinal].


In the exploratory factor analysis we used 'principal axis" factor extraction method [@watkinsStepbyStepGuideExploratory2020]. A posterior sampling adequacy was estimated using KMO statistics [@kaiserIndexFactorialSimplicity1974]. TO identify the optimum number of factors required to explain the latent structure of our scale we used Scree plot [@cattellScreeTestNumber1966a], Horn's parallel analysis [@hornRationaleTestNumber1965], Hull method [@lorenzo-sevaHullMethodSelecting2011] and Minimum average partials method (MAP) [@velicerDeterminingNumberComponents1976]. Lastly, to identify the simple structure, we followed the following guidelines  (i) no factors with fewer than three items (ii) no factors with a factor loading <0.3 (iii) no items with cross-loading greater than .3 across factors [@childEssentialsFactorAnalysis2006a; @mulaikFoundationsFactorAnalysis2009; @watkinsStepbyStepGuideExploratory2020] 

### Results & Discussion

```{r, gtfig, include =F}

gt.data <- na.omit(efa.data)

names(gt.data)[names(gt.data) == "RCS02"] <- "CS02"
names(gt.data)[names(gt.data) == "RCS05"] <- "CS05"

#Creating long data
gt.data.long <- as.data.frame(gather(gt.data, Items, value))
gt.data.long$value <- as.numeric(as.character(gt.data.long$value))


gt.data.tab <- gt.data.long %>% 
  group_by(Items) %>% 
  # calculate summary stats & create data for the histogram and density plot
  dplyr::summarise(
    nr = n(),
    mean = mean(value, na.rm = TRUE),
    med = median(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    hist_data = list(value),
    dens_data = list(value),
    .groups = "drop"
  ) %>% 
  gt() 


gt.likert <-  as.data.frame(gt.data)


#gt.likert <-  mutate(gt.likert, across(starts_with("ASQ"), ~unname(recod[.])))

gt.likert.Factor = as.data.frame(lapply(gt.likert,factor,
                                     ordered = T))


#get the items name
gt.items <- names(gt.likert.Factor) 
#Calculate percentage
gt.percentage <- kutils::likert(gt.likert.Factor, vlist = gt.items ) 

gt.percentage <- gt.percentage$table %>% 
  as.data.frame(.)

#data wrangling
labels <- c("never", "rarely","sometimes", "often", "always","Total")
as.data.frame(labels)

full.percentage <- cbind(labels,gt.percentage) #tables with labels  
full.percentage<- t(full.percentage ) #transpose
as.data.frame(full.percentage)
full.percentage1 <- full.percentage[-1,-6] #removing 1st row and total column
#full.percentage2 <- full.percentage1[, c(3, 4, 1, 2,5)]# rearranging
as.data.frame(full.percentage1)


colnames(full.percentage1) <- c("Never", "Rarely","Sometimes", "Often", "Always")

Items <- rownames(full.percentage1)
as.data.frame(Items)
full.percentage3 <- cbind(Items,full.percentage1)

full.percentage3 <- full.percentage3[order(Items),] 
full.percentage3 <- as.data.frame(full.percentage3[,-1]) 

full.percentage3 <- full.percentage3%>% 
  gt()


gt.table <- gt.data.tab$'_data'
gt.liket <- full.percentage3$"_data"


Table <-  cbind( gt.table, gt.liket )%>% 
  gt()%>% 
  # histogram and density plots
  gtExtras::gt_sparkline(
    hist_data,
    type = "histogram",
    line_color = "black", 
    fill_color = "#00A08799",
    bw = 1,
    same_limit = TRUE)%>%
  gtExtras::gt_sparkline(
    dens_data,
    type = "density",
    line_color = "black", 
    fill_color = "#E64B3599",
    bw = 0.75,
    same_limit = TRUE
  )%>%
  # format decimals
  fmt_number(columns = mean:sd, decimals = 1) %>%
  # header
  tab_header(
    title = md("**Communication**"),
    subtitle = md("Summary Descriptives")
  ) %>% 
  tab_footnote(
    footnote = md("**Histogram**"),
    locations = cells_column_labels(columns = hist_data)
  ) %>%
  tab_footnote(
    footnote = md("**Density**"),
    locations = cells_column_labels(columns = dens_data)
  ) %>% 
  #create groups of columns
  tab_spanner(
    label = "Items",
    columns = Items
  ) %>%
  tab_spanner(
    label = "Summary Statistics",
    columns = nr:sd
  ) %>%
  tab_spanner(
    label = "Graphics",
    columns = hist_data:dens_data
  )  %>%
  # change column names to appear in the table
  cols_label(
    Items = ("Items"),
    nr = ("n"),
    mean = ("Mean"),
    med = ("Median "),
    sd = (("SD")),
    hist_data = "Histogram",
    dens_data = "Density"
  ) %>%
  
  tab_spanner(
    label = "Response Pattern",
    columns = "Never":"Always"
  ) %>%
  # set alignment as per wish
  cols_align(
    align = "center",
    columns = everything()
  ) %>%
  opt_align_table_header(align = "left") %>%
  gtExtras::gt_plt_dot(
    mean,
    Items,
    palette = "ggthemes::fivethirtyeight")


gtsave(Table, "Figures/efa_communication.png",vwidth = 7000)
  
```

```{r ggplot2, include=F}
#This chunk holds code for creating ggplot2 based apatheme for plots.
apatheme=theme_bw()+
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        #text=element_text(family = "Helvetica"),
        axis.text.x = element_text(size = 15),
        axis.text.y = element_text(size = 15),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        plot.title = element_text(size = 15),
        legend.text = element_text(size = 15),
        legend.title=element_blank(),
        axis.line.x = element_line(color='black'),
        axis.line.y = element_line(color='black'),
        panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))

```

```{r EFAdata, include=FALSE}

#library(VIM)
missing <- VIM::aggr(efa.data, plot =T)

```

```{r CorrMatrix, include=FALSE}
#Polychoric Correlation matrix

correlations <- psych::polychoric(efa.data)
upper <- correlations$rho[upper.tri(correlations$rho, diag = F)]

correlationtab <- as.data.frame(upper )



min.cor <- apa(min((upper)),2,F) #minimum cor.coefficient of the matrix
max.cor <- apa(max((upper)),2,F) # max. correlation coefficient of the matrix

determinets <- det(correlations$rho) 
# Calculating the percentage of correlations higher than .30

BigR = sum(correlations$rho >= abs(.30) & correlations$rho < abs(1.0), na.rm =T)/2 
totR = length(efa.data)*(length(efa.data)-1)/2
cor.per <- print (BigR/totR)*100
```

```{r, include = F}
cor.mat <- correlations$rho
cor.mat <- as.data.frame(cor.mat)
```

```{r results='asis'}
apa_table(cor.mat,landscape = T )
```

```{r item-analysis, include=FALSE, results='asis'}
Cron.bach <- psych::alpha(correlations$rho,check.keys=TRUE) 
Cron.bach$total %>% 
  knitr::kable(caption = "Alpha", digits = 2) 
Cron.bach$alpha.drop %>% 
  knitr::kable(caption = "Alpha value if item is dropped", digits = 2) 
Cron.bach$item.stats %>% 
  knitr::kable(caption = "Corrected Item total Correlation", digits = 2) 


low.r.corec <- (min(Cron.bach$item.stats$r.cor))  #minimum item total correlation
high.r.corec <- (max(Cron.bach$item.stats$r.cor))     # maximum item total correlation

ordinal.alpha <- Cron.bach$total$raw_alpha
ordinal.alpha.drop <- as.data.frame(Cron.bach$alpha.drop$raw_alpha)
minimum.ordinal.alpha.drop <- min(ordinal.alpha.drop )
maximum.ordinal.alpha.drop <- max(ordinal.alpha.drop )
```

```{r EFAassumptions, include=FALSE}

#KMO test
KMO <- psych::KMO(efa.data) 

# Test of correlation matrix
bartlet <- psych::cortest.bartlett(efa.data, n =300)

decriptives <- tabledown::des.tab(efa.data)
decriptives <- cbind(decriptives, ordinal.alpha.drop )
colnames(decriptives) = c("Items","Mean", "SD", "Skew", "Kurtosis", "Shapiro-Wilk Statistics","Item-Total Correlation", "Alpha Drop")
descriptives <- cbind()

item.total.correlation <- range(decriptives$`Item-Total Correlation`)
```


#### Sampling adequacy

Kaiser-Meyer-Olkin (KMO) [@kaiserIndexFactorialSimplicity1974] statistics was used to check the sampling adequacy.  The overall KMO value for 23 items was `r apa(KMO$MSA,2,T)`, which was above the cut-off value of .50, indicating an adequate sample.

#### Descriptive statistics and item analysis

Table\@ref(tab:tab-des) reports univariate descriptive statistics for the 23 items. All items were skewed and violated univariate normality assessed by  The Shapiro-Wilk test indicated all the items violated normality assumptions [@shapiro1965analysis]. Mardia's Test of multivariate normality [@mardiaMeasuresMultivariateSkewness1970] yielded Multivariate skew = 4030.49 (p <0.001) and multivariate kurtosis = 15.1 (p <0.001) indicating the violation of multivariate normality as well. As such we used polychoric correlation matrix which is more robust towards these violations. Our initial item analysis yelled internal consistency coefficient ordinal alpha = `r apa(ordinal.alpha,2,T)`. Alpha drop statistics (Table\@ref(tab:tab-des)) showed no substantial increase of ordinal alpha if any item is deleted and ranged between `r round(minimum.ordinal.alpha.drop,2)`-`r apa(maximum.ordinal.alpha.drop,T)`. As such we subjected all items to EFA.

Supplementary Table 1 and Figure \@ref(fig:figCor) depict the inter-item correlation coefficients of BCS. Bartlett’s test of sphericity [@RN1261], $\chi^2$ (`r bartlet$df`) = `r bartlet$chisq`, p < .001 indicated the inter-item correlations are significantly different than zero. However, only `r apa(cor.per,2,T)`% of the inter-item correlation coefficients were greater than absolute value of .30 in the obtained matrix. The corrected item-total correlations range was `r min(item.total.correlation)`-  `r max(item.total.correlation)` (Table\@ref(tab:tab-des)).

```{r tab-des}
apa_table(decriptives)
```

```{r corplot, include =F}
#This chunk holds code for plotting the correlation matrix

p.mat <- correlation::cor_to_p(correlations$rho, 428, method = "polychoric")


corplot <- ggcorrplot(correlations$rho, p.mat=p.mat$p, insig = "pch", hc.order = FALSE, outline.col = "white", type = "lower", legend.title = "Correlation",sig.level = 0.05, pch.cex=1.8,
                      # insig = "blank",
           ggtheme = ggplot2::theme_minimal(),tl.srt = 90,colors = c("#E64B35FF", "white", "#3C5488FF") )+
  theme( panel.grid.major = element_blank(),
         axis.text.x = element_text(size = 8),
         axis.text.y = element_text(size = 8),
         panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))


ggsave("Figures/tiff/corplot.tiff",corplot, width = 3.5, height = 3.5, dpi = 600, compression = "lzw", bg ="White" )
ggsave("Figures/600/corplot.png",corplot, width = 3.5, height = 3.5, dpi = 600, bg ="White" )

```

(ref:figCor) Inter item polychoric correlation coefficients for the 23 items. 11.56 % inter-item correlation coefficients were higher than |.30|

```{r figCor, out.height="150%",out.width="100%", fig.align= 'center', fig.cap='(ref:figCor)', results='asis', fig.align='center'}

knitr::include_graphics('Figures/tiff/corplot.tiff', dpi =600)

```


```{r ParallelEFA, include=FALSE}
#This chunk holds code for factor identification method : Horn
# Parallel analysis
Horn <- paran(efa.data, iterations=500, centile=0, quietly=FALSE,
           status=TRUE, all=FALSE, cfa=TRUE, graph=TRUE,
           color=TRUE, col=c("black","red","blue"),
           lty=c(1,2,3), lwd=1, legend=TRUE, 
           width=640, height=640, grdevice=png, seed=0)


Adjusted.EV <- data.frame(Horn$AdjEv)
Adjusted.EV$type = c('Adjusted Ev')
Adjusted.EV$num = c(row.names(Adjusted.EV))
Adjusted.EV$num = as.numeric(Adjusted.EV$num)
colnames(Adjusted.EV) = c('eigenvalue', 'type', 'num')


Random.EV <- data.frame(Horn$RndEv)
Random.EV$type = c('Random EV')
Random.EV$num = c(row.names(Random.EV))
Random.EV$num = as.numeric(Random.EV$num)
colnames(Random.EV) = c('eigenvalue', 'type', 'num')


Unadjusted.EV <- data.frame(Horn$Ev)
Unadjusted.EV$type = c('Unadjusted EV')
Unadjusted.EV$num = c(row.names(Unadjusted.EV))
Unadjusted.EV$num = as.numeric(Unadjusted.EV$num)
colnames(Unadjusted.EV) = c('eigenvalue', 'type', 'num')



parallel = ggplot(Adjusted.EV, aes(x=num, y=eigenvalue, shape=type, color=type)) +
  #Add lines connecting data points
  geom_line(colour ='#DC000099')+
    #geom_line(data = Random.EV) +
  #geom_line(data = Unadjusted.EV)+
    #Add the data points.
  geom_point(size=1.5,colour ='#3C5488FF')+
  #geom_point(data = Random.EV, size=3)+
  #geom_point(data = Unadjusted.EV, size=3)+
  scale_y_continuous(name="Eigen Value", limits=c(0, 5), breaks=seq(0,5,1)) +
   #Label the x-axis 'Factor Number', and ensure that it ranges from 1-max # of factors, increasing by one with each 'tick' mark.
  scale_x_continuous(name='Factor Number (Parallel Analysis)', limits=c(0, 24),breaks=seq(0,24,4))+
    #Add vertical line indicating parallel analysis suggested max # of factors to retain
  geom_hline(yintercept=1, linetype = 'dashed') + apatheme +theme(,legend.position = "None") 
#text = element_text(size = 25)

```

```{r ScreePlot, include=FALSE}

#This chunk holds code for factor identification method : Scree Plot

Scree <- scree(correlations$rho,factors=TRUE,pc=TRUE,main="(B)",
      hline=NULL,add=F)


FA.Scree <- data.frame(Scree$fv)
FA.Scree$type = c('Factor Analysis')
FA.Scree$num = c(row.names(FA.Scree))
FA.Scree$num = as.numeric(FA.Scree$num)
colnames(FA.Scree) = c('eigenvalue', 'type', 'num')

PA.Scree <- data.frame(Scree$pcv)
PA.Scree$type = c('Principal Component Analysis')
PA.Scree$num = c(row.names(PA.Scree))
PA.Scree$num = as.numeric(PA.Scree$num)
colnames(PA.Scree) = c('eigenvalue', 'type', 'num')


scree.plot <-ggplot(FA.Scree, aes(x=num, y=eigenvalue,color=tye, shape=type))+
   geom_line(colour ='#DC000099')+
  #geom_line(data = PA.Scree)+ 
  geom_point(size=1.5,colour ='#3C5488FF')+
  #geom_point(data = PA.Scree, size=3)+
  scale_y_continuous(name="Eigen Value", limits=c(0, 5), breaks=seq(0,5,1)) +
  scale_x_continuous(name='Factor Number (Scree Plot)', limits=c(0, 20),breaks=seq(0,20,4))+
  geom_hline(yintercept=1, linetype = 'dashed') + apatheme +theme(legend.position = "None") 
#text = element_text(size = 25

```

```{r HullEFA, include=FALSE}
#This chunk holds code for factor identification method : Hull

# HULL
EFA.MRFA::hullEFA(efa.data,extr = "ULS", index_hull = "CAF", display = TRUE, graph = T,
        details = TRUE)
hull <- ggplot2::last_plot()
Hull <- hull+ ggtitle(NULL)+xlab("Factor Number (Hull Method)")+ylab("CAF")+ aes(color = '#DC000099')+geom_point(color ='#3C5488FF',size =1)+
  apatheme +theme(legend.position = "None") +scale_fill_identity()




```

```{r MAPefa, include=FALSE}
#This chunk holds code for factor identification method : MAP
#MAP
map <- psych::VSS(efa.data, rotate = "promax", fm = 'pa', n.obs =300 )
map.map <- as.data.frame(map$map)
colnames(map.map) <- "MAP Statistic"
map.statistics <- map$vss.stats[,c(1,2,5,6,7,10,11)]
full.map <- cbind(map.map,map.statistics)

```

```{r map}
papaja::apa_table(full.map, caption = "Minimum average partial (MAP) method of factor numder determination. MAP Statistics is the lowest in the 5th row indicating five factors are required.")
```


#### Test-retest reliability

```{r ICC}
ICC <- psych::ICC(all.item.icc)
papaja::apa_table(ICC$results, caption = "Intra Class Correlation.")
```


#### Exploratory factor analysis

To identify optimum number of factor required to express the latent structure adequately we at first used the Scree-plot [@cattellScreeTestNumber1966a]. The Scree-plot suggested one factor solution. One factor solution was also supported by MAP method [@velicerDeterminingNumberComponents1976] and Hull method [@lorenzo-sevaHullMethodSelecting2011]. Minimum average partial (MAP) method  expects the average squared off-diagonal values of the calculated partial correlation matrix to be minimum when the correct number of factors are extracted [@velicerDeterminingNumberComponents1976]. In our data set this value reached the minimum after extracting the first factor (Supplementary Table 2). Hull method tried to find an optimal number of factors to balance model fit and the number of parameters and offered one factor solution in our data set (Figure \@ref(fig:facIdFig)). 

```{r factors, include=F}
#This chunk holds code for compiled factor identification plots

factor <- cowplot::plot_grid(scree.plot,Hull, 
                   labels = "AUTO",
                   ncol=2, 
                  align = "h", 
                  label_fontfamily = "sans",
                  label_fontface = "plain")
ggsave("Figures/600/factors.png",factor, width = 7, height = 3.5, dpi = 600)

ggsave("Figures/tiff/factors.tiff",factor, width = 7, height = 3.5, dpi = 600)
```

(ref:facIdFig) Factor Identification Methods (A) Scree plot suggested one factor. (B) Hull method indicated one factor were required to balance the model fit and number of parameters.

```{r facIdFig, fig.align= 'center', fig.cap='(ref:facIdFig)',  warning=FALSE, results= 'asis'}

knitr::include_graphics("Figures/tiff/factors.tiff", dpi =600)

```


```{r EFA2f, eval=FALSE, include=FALSE}
fa.2F.1 <- fa(r=correlations$rho, nfactors = 2, fm= "pa",rotate ="promax",
              residuals = TRUE, SMC = TRUE)
AA <- print(fa.2F.1, cut = .3, digits = 3, sort = TRUE)


reduced.model.2F.1 <- dplyr::select(efa.data ,
                                    -c( CS09, CS03, CS16, CS01, RCS05))

correlations.red.2F.1 <- polychoric(reduced.model.2F.1)

fa.2F.2 <- fa(r=correlations.red.2F.1$rho, nfactors = 2, fm= "pa",rotate ="promax",
              residuals = TRUE, SMC = TRUE)

BB <- print(fa.2F.2, cut = .3, digits = 3, sort = TRUE)

reduced.model.2F.2 <- dplyr::select(efa.data ,
                                    -c( CS09, CS03, CS16, CS01, RCS05, RCS02, CS21, CS23))

correlations.red.2F.2 <- polychoric(reduced.model.2F.2)


fa.2F.3 <- fa(r=correlations.red.2F.2$rho, nfactors = 2, fm= "pa",rotate ="promax",
              residuals = TRUE, SMC = TRUE, max.iter = 500 )

CC <- print(fa.2F.3, cut = .3, digits = 3, sort = TRUE)

var1 <- CC$Vaccounted[2,1]*100
var2 <- CC$Vaccounted[2,2]*100

omega <- psych::omega(reduced.model.2F.2,2)

efa.table.1 <- tabledown::fac.tab(fa.2F.3,cut=.3, complexity = F)


#Communality
Fac.2 <- fa.2F.3
min.com <- min(Fac.2$communality)
max.com <- max(Fac.2$communality)

# loading
min.loadings <- (min(Fac.2$loadings))
max.loadings <- (max(Fac.2$loadings))

# Residuals
residual.5F =residuals(fa.2F.3, diag = FALSE, na.rm =T)
#Count of numbers of residuals>.05
BigRR= sum(residual.5F>abs(.05), na.rm =T)
print(BigRR)

#Total number of off diagonal elements in the data matrix
totRR = length(reduced.model.2F.2)*(length(reduced.model.2F.2)-1)/2

# Proportion of off-diagonal elements >.05
sumR <- sum(BigRR/totRR*100)

```


```{r tau-equivalance, eval=FALSE, include=FALSE}
tau.equivalance <- coefficientalpha::tau.test(reduced.model.2F.2)
```

```{r ordinal-alpha, eval=FALSE, include=FALSE}
F1 <- dplyr::select(efa.data, CS15, CS22, CS20, CS11, CS14, CS18, CS13, CS06, CS10)
F2 <- dplyr::select(efa.data, CS19, CS04, CS17, CS12, CS08, CS07) 

#ordinal alpha
F1.alpha <- psych::alpha(polychoric(F1)$rho,check.keys=TRUE)
F2.alpha <- psych::alpha(polychoric(F2)$rho,check.keys=TRUE)

F1.alpha <- F1.alpha$total$raw_alpha
F2.alpha <- F2.alpha$total$raw_alpha


```


```{r EFA1f,  include=FALSE}
fa.1F.1 <- fa(r=correlations$rho, nfactors = 1, fm= "pa",
              residuals = TRUE, SMC = TRUE)
DD <- print(fa.1F.1, cut = .3, digits = 3, sort = TRUE)


reduced.model.1F.1 <- dplyr::select(efa.data ,
                                    -c( CS16, RCS02, RCS05, CS01, CS09, CS23))

correlations.red.1F.1 <- polychoric(reduced.model.1F.1)

fa.1F.2 <- fa(r=correlations.red.1F.1$rho, nfactors = 1, fm= "pa",
              residuals = TRUE, SMC = TRUE)

EE <- print(fa.1F.2, cut = .3, digits = 3, sort = TRUE)
var3 <- EE$Vaccounted[2,1]*100

one.factor.alpha <- psych::alpha(correlations.red.1F.1$rho ,check.keys=TRUE)
one.factor.alpha <- one.factor.alpha$total$raw_alpha
```


```{r 1f-tau-equivalance, eval=FALSE, include=FALSE}
tau.equivalance.2 <- coefficientalpha::tau.test(reduced.model.1F.1)
```
The initial solution of the fitted one factor model had six items with poor factor loadings (Item 1, 2,5,9, 16, 23). We discarded these items from the model and run another EFA. This iteration of EFA yielded a one factor simple structure with 17 items. The one factor solution explained `r apa(var3,2,T)`% of the total variance.  The internal consistency reliability coefficient for this model was, ordinal $\alpha$ = `r apa(one.factor.alpha,2,F)`.




```{r eval=FALSE, include=FALSE}
model.0 <- "F1 =~ CS15 + CS22+CS20+CS11+CS14+CS18+CS13+CS06+CS10
            F2 =~ CS19+CS04+CS17+CS08+CS07"
fit.0 <- cfa(model.0, data = cfa.data, estimator = "WLSMV") 

## Summary of Model 
cfa.sum.0 <- summary(fit.0, fit.measures =TRUE,standardized = TRUE,rsq =TRUE)


## Selected Fit measures 
fit.measures.0 <- fitmeasures (fit.1,c("gfi", "agfi", "nfi","rfi", 
                       "cfi","tli",
                       "rmsea", "rmsea.ci.lower", "rmsea.ci.upper","srmr"))
reliability0 <- semTools::reliability(fit.1, return.total = T)

```


# Study 2 Confirmation of Factor Structure and Psychometric Properties of Bangla Communication Scale

This study had four objectives. First, we confirmed the one factor solution of our scale obtained in Study-1 and estimated the reliability of the scale. Second, to gather convergent validity evidence of BCS. Third, we established gender-based measurement invariance of Bangla Communication Scale.  Lastly, we assessed item discrimination, item difficulty and precision of BCS using Item Response Theory Based Analysis

## Method

### Participants
```{r cfades}
cfa.desc.1<- cfa.data.full[,c(3,4,5)]
validity.des.1 <- validity.data.full[,c(3,4,5)]
## Recoding desc$Sex
cfa.desc.1$Gender <- fct_recode(cfa.desc.1$Gender,
  "Boy" = "male",
  "Girl" = "female"
)
colnames(cfa.desc.1) <- c("Gender", "Age", "Socio Economic Status")


## Recoding desc$Sex
validity.des.1$Gender <- fct_recode(validity.des.1$Gender,
  "Boy" = "male",
  "Girl" = "female"
)
colnames(validity.des.1) <- c("Gender", "Age", "Socio Economic Status")


cfa.des_tab.1 <- cfa.desc.1 %>%
  tbl_summary(
    by = Gender,
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                     all_categorical() ~ "{n} ({p}%)"),
    type = list(Age ~ 'continuous'),
    digits = all_continuous() ~ 2,
    
    missing = "no"
    ) %>% add_overall() %>% bold_labels() %>% 
modify_header(label ~ "**Variable**")  %>%
  modify_caption("Demographic Characteristics")  

as_tibble(cfa.des_tab.1) -> cfa.desc_tibble
as_kable_extra(cfa.des_tab.1, format = "latex",booktabs = T) -> desc_kable #save it as a knitr::kable




validity.des_tab.1 <- validity.des.1 %>%
  tbl_summary(
    by = Gender,
    statistic = list(all_continuous() ~ "{mean} ({sd})",
                     all_categorical() ~ "{n} ({p}%)"),
    type = list(Age ~ 'continuous'),
    digits = all_continuous() ~ 2,
    
    missing = "no"
    ) %>% add_overall() %>% bold_labels() %>% 
modify_header(label ~ "**Variable**")  %>%
  modify_caption("Demographic Characteristics")  

as_tibble(validity.des_tab.1) -> validity.desc_tibble
as_kable_extra(validity.des_tab.1, format = "latex",booktabs = T) -> desc_kable #save it as a knitr::kable






cfa.des.2 <- cfa.desc.1 %>% 
  psych::describeBy("Gender")

validity.des.2 <- validity.des.1%>% 
  psych::describeBy("Gender")

cfa.female <- as.tibble(cfa.des.2$Girl)
cfa.male <- as.tibble(cfa.des.2$Boy)


validity.female <- as.tibble(validity.des.2$Girl)
validity.male <- as.tibble(validity.des.2$Boy)

```

A second group of `r nrow(cfa.data.all)` students of grade 8-12 from eight schools participated in Study-2. They were recruited using convenience sampling method. One participant's data were excluded for missing data. In the complete dataset of `r nrow(cfa.data)`,  `r cfa.female[1,2]` were female aged between `r cfa.female[2,8]` to `r cfa.female[2,9]` years (`r round(cfa.female[2,3],2)` ± `r round(cfa.female[2,4],2)`). `r cfa.male[1,2]`  were male with an age range between `r cfa.male[2,8]` participants `r cfa.male[2,9]` years (`r round(cfa.male[2,3],2)` ± `r round(cfa.male[2,4],2)`). `r cfa.desc_tibble [4,2]` participants belonged to middle socio-economic status. `r cfa.desc_tibble [3,2]` and `r cfa.desc_tibble [5,2]` participants belonged to lower and upper socio-economic status-respectively. To assess the sampling adequacy we followed the N:q rule [@bentlerPracticalIssuesStructural1987a; @RN1241] where 10 participants per item is required to earn trustworthiness of the result. Our sample size exceeded the requirement as we had 17 items. 

A subset of Study-2 sample (n=`r nrow(validity.data)`) responded to both Bangla Beck Hopeless Scale and Bangla Communication Scale. Among them `r validity.female[1,2]` were female aged between `r validity.female[2,8]` to `r validity.female[2,9]` years (`r round(validity.female[2,3],2)` ± `r round(validity.female[2,4],2)`). `r validity.male[1,2]`  were male with an age range between `r validity.male[2,8]` participants `r validity.male[2,9]` years (`r round(validity.male[2,3],2)` ± `r round(validity.male[2,4],2)`). `r validity.desc_tibble [4,2]` participants belonged to middle socio-economic status. `r validity.desc_tibble [3,2]` and `r validity.desc_tibble [5,2]` participants belonged to lower and upper socio-economic status-respectively

### Measures


#### Bangla Beck Hopelessness Scale

```{r beck-hopelessness, include =F}
hopelessness<- validity.data.full %>% 
  dplyr::select( HS01:HS20) 
#ordinal alpha
hopelessness.alpha <- psych::alpha(hopelessness,check.keys=TRUE)

hopelessness.alpha <- hopelessness.alpha$total$raw_alpha


```


Beck Hopelessness Scale(BHS) is composed of 20 items with a  dichotomous response scale(True/False) [@beck1974measurement]. It captures three major dimensions of hopelessness: Feelings about the future, loss of motivation and expectations [@balsamo2020further]. This scale has nine reversed coded items (items 1, 3, 5, 6, 8, 10, 13, 15, 19) and yield a total score (range 0-20) where a higher score indicates higher disposition towards hopelessness. In this study we have used the Bangla Hopelessness scale [@uddinPsychometricEvaluationBangla]. Bangla Beck Hopelessness Scale retained all 20 items of the original scale and following the same scoring method. Internal consistency K-R coefficient for Bangla Beck Hopelessness Scale in our Study-2 sample was `r apa(hopelessness.alpha,2,T)`



### Analytic strategies

We conducted a categorical confirmatory factor analysis (CFA) with Weighted Last Square with mean and variance adjusted (WLSMV) estimator. The CFA was conducted using 'Lavaan' package in RStudio [@R-lavaan]. To assess the model fit we followed the popular suggestions of @huCutoffCriteriaFit1999: Comparative fit index (CFI) and the Tucker Lewis index (TLI): good fit $\geq$.95, acceptable fit$\geq$.90); the root mean square error of approximation (RMSEA): good fit < .06, acceptable fit <.08; and the standardized root mean square (SRMR) good fit<.08, acceptable fit <.10. 

Measurement invariance (MI) between boys (n= `r cfa.male[1,2]`) and girls (n= `r cfa.female[1,2]`) was analysed by using structure equation  modelling paradigm. Measurement invariance (MI) evaluates whether a construct holds similar meaning  meaning across groups [@RN1241]. We consequtively fitted four nested models: configural, metric, scalar, and residual invariance models and compared them with each others.  The invariance model fit of our tool was assessed using the fit indices including $\chi^2$ test, CFI and TLI (close to .95 or above), RMSEA (close to .06 or below) [@huCutoffCriteriaFit1999]. The comparison among different measurement invariance models was made using the $\chi^2$ difference test ($\Delta \chi^2$)  to assess whether our obtained latent structure attained the highest level of the MI. A non-significant $\Delta \chi^2$ test between two MI models fit indicates mode fit does not significantly decrease for the superior model [@dimitrov2010testing] thus allowing the superior level of invariance model to be accepted.

Convergent validity was investigated by correlational analysis between Bangla Communication Scale and Beck Hopelessness Scale [@uddinPsychometricEvaluationBangla] on a subset of our study-2 sample (n = `r nrow(validity.data)`) 
Lastly, we analysed the item quality of Bangla Communication Scale in terms of item difficulty, item discrimination and item fit statistics. IRT judges an item’s quality by providing item information (difficulty & discrimination) in the light of participants’ trait level $\theta$. The precision of the Bangla Scale was inspected using Test information Curve obtained from the fitted IRT model. In IRT based analysis our aim was only to assess the quality of the items in our Bangla Communication Scale. 

Lastly, we analysed the item quality of Bangla Communication Scale using "Item Response Theory" (IRT). We fitted a graded response model [@samejima1997handbook] to the combined study-1 and study-2 sample (n =`r nrow(irt.data)`). IRT assess the item quality by estimating item difficulty, item discrimination, item information, and test information [@bakerBasicsItemResponse2017]. Item discrimination indicates the pattern of variation in the categorical responses with the changes in latent trait level ($\theta$), and item information curve (IIC) indicates the amount of information an item carries along the latent trait continuum. Here, we reported  the item discrimination parameter and categorize the items according to the suggestions of @bakerBasicsItemResponse2017 : none = 0; very low =0.01 to 0.34; low = 0.35 to 0.64; moderate = 0.65 to 1.34 ; high = 1.35 to 1.69; very high >1.70. We also assessed the precision of the Bangla Communication using Test information curve (TIC). TIC  indicates the amount of information an the full-scale carry along the latent trait continuum. Item fit and person-fit of the fitted model were also analyzed to gather more evidence on validity and meaningfulness of our Tool [@desjardinsHandbookEducationalMeasurement2018]. Item-fit was evaluated using  the RMSEA value obtained from Signed-$\chi^2$ index implementation, RMSEA value $\le$.06 was considered adequate item fit. Person fit was estimated using standardized fit index Zh statistics [@drasgow1985appropriateness]. Zh < -2 was be considered as a misfit [@drasgow1985appropriateness]. 

### Results & Discussion

#### Confirmatory Analysis and Reliability Estimation 


```{r CFAitems, include=FALSE }
#This chunk holds codes for 1st CFA 

model.1 <- "Communication =~ CS15 + CS21 +CS11 + CS20+ CS14+ CS19+ CS22+ CS12+ CS06+ CS07+ CS18+ CS08+        CS04+CS17+CS03+CS13+CS10" 


fit.1 <- cfa(model.1, data = cfa.data, ordered = names(cfa.data), estimator = "WLSMV") 

## Summary of Model 
cfa.sum.1 <- summary(fit.1, fit.measures =TRUE,standardized = TRUE,rsq =TRUE)


## Selected Fit measures 
fit.measures.1 <- fitmeasures (fit.1,c("gfi", "agfi", "nfi","rfi", 
                       "cfi","tli",
                       "rmsea", "rmsea.ci.lower", "rmsea.ci.upper","srmr"))

tab1 <-  tabledown::cfa.tab(fit.1,   robust = F)

reliability1 <- semTools::reliability(fit.1)

```


Table\@ref(tab:Unitab) summarizes the model fit of Bangla Communication Scale. The fitted model exhibited a significant $\chi^2$ statistic. However, $\chi^2$ statistic is well known for its sensitivity towards sample size [@brownConfirmatoryFactorAnalysis2015a]. As such more emphasize were given towards other fit indices. Other fit indices indicated acceptable fit of the fitted one factor model. The internal consistency reliability coefficients Ordinal $\alpha$ was `r apa(reliability1[2,1],2,F)` which was satisfactory. Figure \@ref(fig:figcfa) depicts the fitted model.

```{r Unitab, results='asis'}
apa_table(tab1, caption = "Model-Fit of Bangla Communication Scale ")
```


```{r mod1, eval=FALSE, include=FALSE}
#This chunk holds codes for modification indices for 1st CFA
modfit.Cor.one <- modindices(fit.Cor.1, sort. = TRUE) 
modfit.Cor.one[modfit.Cor.one$mi>3.84,]
```

```{r cfaplot, include =F}
#This chunk holds codes to store CFA plot


tiff(filename="Figures/tiff/CFAplot.tiff", 
    type="cairo",
    units="in", 
    width=3.5, 
    height=3.5, 
    pointsize=12, 
    res=600)
semPaths (fit.1 , 
          what= "std",
          #"hide", #(hides coefficeits)
          #whatLabels = "std",
          intercepts = F,
          style ="OpenMx",
          #residScale = 6,
          theme = "colorblind",
          nCharNodes = 0,
          reorder =T,
          rotation =2,
          layout ="tree",
          cardinal = T,
          curvePivot =T,
          sizeMan =8,#items length
          sizeMan2 = 2,#items
          sizeLat = 12,#factors
          thresholds = FALSE,
          equalizeManifests =F,
          fade = FALSE,
          edge.label.cex = .8,
          #exoCov = T,
          centerLevels = T,
          #edge.color="black",
          label.scale=T,
          label.cex=1.2, #Font of factor and item name
          residuals=FALSE,
           #exoVar=FALSE,
          #fixedStyle=6, #Style of arrow (guide item)
          #freeStyle=1#Style of arrow (other item), #XKCD = TRUE
           
          )


dev.off()
```

```{r Shortcut Invariance, eval=FALSE, include=FALSE}
invariance.data <- cfa.data.full[, c(3, 6:28)]
invariance.data <- na.omit(invariance.data )
library("semTools")
invariance.model <- measurementInvariance(model = model.1,
                                          data = invariance.data,
                                          group = "Gender",                                                                         estimator = "WLSMV",
                                          strict = T)
invariance.model[[1]] #configural Invariance
invariance.model[[2]] # loading, weak, metric
invariance.model[[3]] # intercept, strong, scaler
invariance.model[[4]] # residual, strict
invariance.model[[5]] # means, structural invariance
```

```{r figcfa, fig.cap = "CFA Plot.", warning=FALSE}

knitr::include_graphics("Figures/tiff/CFAplot.tiff", dpi =600)


```

#### Measurement Invariance

We tested measurement invariance in our study-2 sample across two groups boys (n= `r cfa.male[1,2]`) and girls (n= `r cfa.female[1,2]`).Table \@ref(tab:InvarianceTab) indicates our fitted model had acceptable fit indices for all of the fitted MI models. The model fit did not significantly decrease across the nested models indicating the acceptability of the highest measurement invariance model : residual model.

```{r InvarianceAnalysis_data, include=FALSE}
#This chunk holds codes to prepare measurement invariance data.

invariance.data <- cfa.data.full[, c(3, 6:28)]
invariance.data <- na.omit(invariance.data )
mi.count <- invariance.data %>% 
  group_by(Gender) %>% 
  count() %>% 
  as.data.frame()
```


```{r Invariancedetail, include=FALSE}
#This chunk holds codes for measurement Invariance
library(lavaan)
model.1 <- "Communication =~ CS15 + CS21 +CS11 + CS20+ CS14+ CS19+ CS22+ CS12+ CS06+ CS07+ CS18+ CS08+        CS04+CS17+CS03+CS13+CS10" 

# Configural invariance ####
configural <- cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                  estimator = "WLSMV")

summary(configural, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)

fitmeasures (configural,c("gfi", "agfi", "nfi","rfi", 
                       "cfi","tli",
                       "rmsea", "rmsea.ci.lower", "rmsea.ci.upper","srmr"))

#Metric
weak <- cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                 
                  estimator = "WLSMV", 
            group.equal = "loadings")
            
summary(weak, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)


fitmeasures (weak,c("gfi", "agfi", "nfi","rfi", 
                       "cfi.scaled","tli.scaled",
                       "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled","srmr"))

First.comp <- compareFit (configural, weak)
lavaan::summary(First.comp)



#Scaler
strong <- cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                  
                  estimator = "WLSMV", 
              group.equal = c("loadings", "intercepts"))
summary(strong, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)

Second.comp <- compareFit  (weak, strong)
summary(Second.comp)

#residual
strict <- cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                  
                  estimator = "WLSMV",  
              group.equal = c("loadings", "intercepts", "residuals")) 

summary(strict, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)
residual.fitm <- as.data.frame(fitmeasures (strict,c("gfi", "agfi", "nfi","rfi", "cfi","tli","rmsea", "srmr","aic")))

Third.comp <- compareFit(strict,strong)
summary(Third.comp)
#structural
structural <-cfa(model = model.1,
                  data = invariance.data,
                  group = "Gender",
                  
                  estimator = "WLSMV",  
                 group.equal = c("loadings", "intercepts", "residuals", "means","lv.variances","lv.covariances"))

summary(structural, fit.measures =TRUE,standardized = TRUE, rsq =TRUE)
fitmeasures (structural,c("gfi", "agfi", "nfi","rfi", "cfi","tli","rmsea", "srmr","aic"))

fourth.comp <- compareFit  (structural,strict)
summary(fourth.comp)
comfit.par <- compareFit(configural, weak, strong, strict)
summary (comfit.par)

models <-  list("Configural" = configural, 
                "Metric" = weak, 
                "Scalar" = strong, 
                "Residual" = strict)



Invariance.table <- compareLavaan(models,
              nesting = "Configural > Metric > Scalar > Residual", 
              fitmeas = c("chisq", "df",  "cfi","tli","rmsea", "rmsea.ci.lower", "rmsea.ci.upper", "srmr" ),
              scaled = F,
              chidif = T, digits = 2)

colnames(Invariance.table) <- c("Chi-Square", "df", "CFI", "TLI", "RMSEA", "RMSEA 90% Lower CI", "RMSEA 90% Upper", "Chi-Square Difference", "df difference*", "p")


```

```{r InvarianceTab, results='asis'}
apa_table(Invariance.table, align = "c",  caption = "Measurment Invariance analysis on CFA sample (n=262) across native and non-native English speakers.", note = " a = Metric vs Configural; b = Scalar vs Metric; c = Residual vs Scalar; * =  df of model comparison", landscape = T, font_size = "footnotesize" )

```

#### Item Response Theory guided item analysis

```{r samplesizeIRT, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, results='hide', width=60}
set.seed(222)
m <-  23 # item number
n <- c(50, 75, 100, 150, 200, 300, 350) # sample size
design <- as.data.frame(n)


irtGenerate <- function(condition, fixed_objects = FALSE) {
n <- condition$n

a <- matrix(rlnorm(m,.2,.3))
diffs <- t(apply(matrix(runif(m*4, .3, 1), m), 1, cumsum))
diffs <- -(diffs - rowMeans(diffs))
diffs<- diffs + rnorm(m)
d <- diffs
dat <- simdata(a, d, n, itemtype = 'graded')
return(dat)
}

irtAnalyze <- function(condition, dat, fixed_objects = NULL) {
mod <- mirt(dat, 1, itemtype = 'graded', verbose = FALSE)
simpars <- coef(mod, simplify = TRUE, digits = Inf)$items
irtpars <- c(a = simpars[,1], d = simpars[,2])
return(irtpars)
}

irtSummarize <- function(condition, results,
fixed_objects = NULL) {
apop <- fixed_objects['alpha', ]
dpop <- fixed_objects['d', ]
simrmse <- RMSE(results, c(apop, dpop))
out <- c(RMSE = simrmse)
return(out)
}


simres <- runSimulation(design, replications = 100,
parallel = TRUE, generate = irtGenerate,
analyse = irtAnalyze, summarise = irtSummarize,
packages = c('mirt'))
simres


colind <- grep(".a.", colnames(simres))
sima <- as.data.frame(simres[, colind])
nvec <- as.numeric(simres$n)

meanRMSE <- rowMeans(sima)
names(meanRMSE) <- n
round(meanRMSE, 2)
matplot(nvec, log(sima), type = "l", col = 1, lty = 1,
ylab = "log(RMSE)", xlab = "sample size",
main = "Graded Response Model", xaxt = "n")
axis(1, at = nvec)
```

We did a Monte Carlo simulation using "SimDesign" package [@R-SimDesign]  with sample sizes varying from 50-350 and calculated average root mean squared error(RMSE) to estimate the optimal sample size for the graded response model with 23 items. The RMSE became stable for n = 200 to 300 (RMSE ranging between .25-.35). Our sample size exceed the estimated sample size for stability.

```{r, include =F}
irt.data <- na.omit(irt.data)
irt.data.1 <- irt.data %>% 
  dplyr::select( CS03, CS04, CS06, CS07,CS08,CS10,CS11, CS12, 
                 CS13,CS14,CS15,CS17, CS18, CS19, CS20 ,CS21, CS22)

fit <- mirt(irt.data.1, model = 1, itemtype = 'graded', 
               SE = TRUE, Se.type = 'MHRM',
               technical = list(NCYCLES = 10000))



# Model Parameters ####
params <- coef(fit, IRTpars = TRUE, simplify = TRUE, rawug = FALSE) 
items <- data.frame(params$items)
se <- coef(fit, printSE = TRUE)

# Model Fit (degrees of freedom too low to check model fit)
model <- M2(fit)


#Item fit
item.fit<- itemfit(fit, fit_stats = c("S_X2", "G2","Zh", "infit"),
                                  impute=10)

#Identifying Missfit items based on RMSEA Value
item_misfits <- subset(item.fit, RMSEA.S_X2 >= .06)



## Creating IRT table
item.fit2 <- item.fit[,c(4,6,11,12,13,14)] 
colnames(item.fit2) <- c("Standardized Outfit", "Standardized Infit", "S-Chi-square", "df", "RMSEA", "p")

IRT.details <- cbind(items ,item.fit2)

IRT.details <- IRT.details %>% 
 dplyr::mutate_if(is.numeric, round, digits=3)

IRT.details <- tibble::rownames_to_column(IRT.details, "Items")
#write_csv(IRT.details, "table_raw/IRT_parameters.csv")

#-3<b<3
#.5<a<2; baker p12

mean.discrimination <- mean(IRT.details$a)
sd.discrimination <- sd(IRT.details$a)
range.descrimination <- range(IRT.details$a)

cat.prob <- IRT.details[,c(3:6)]
cat.prob.long <- reshape::melt(cat.prob)
range.difficulty <- range(cat.prob.long$value)

range.outfit <-  range(IRT.details$Outfit)
range.infit <-  range(IRT.details$Infit)
range.rmsea <- range(IRT.details$RMSEA)






# Person Fit ####

personfit <- personfit(fit) 
personfit_model_misfits <- subset(personfit, Zh < -2)
rownames(personfit_model_misfits)
nrow(personfit_model_misfits)
hist(personfit$Zh, xlab = "Zh Statistics",main = "F1 Person Fit")
abline(v = -2, lwd = 2, lty = 2)




person <- ggplot(personfit, aes(x=Zh)) + geom_histogram(binwidth=.5,col=I("black"),fill="palegreen4")+geom_vline(xintercept = -2)+
  labs( y="Number of Participants", x = "Zh Statistics")+apatheme + xlim(-4,2)+
   scale_y_continuous(limits = c(0, 40), expand = expand_scale(mult = c(0, 0.1)))



# annotation.1 <- data.frame(
#    x = (-3.1),
#    y = (20),
#    label = ("Most of the participants
#         are within the guidline")
# )
# 
# per.anno <-person + geom_label(data=annotation.1, aes( x=x, y=y, label=label),                 , 
#            color="orange", 
#            size=5 , angle=45, fontface="bold" )


ggsave("Figures/600/person.png",person , width = 3.5, height = 3.5, dpi = 600, bg = "white")

ggsave("Figures/tiff/person.tiff",person , width = 3.5, height = 3.5, dpi = 600, bg = "white")

# Plots ####

OCC <- plot(fit, type = "trace", facet =T, main = "Communication Scale OCC")
info <- plot(fit, type = "infoSE", main = "Communication Scale")
iteminfo <- plot(fit, type = "infotrace", 
                    facet_items = T, main = "Communication Scale")





#conditional reliability
reliability <- plot(fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="" )

marginal.rel <- marginal_rxx(fit)

#scale characteristics curve
scale <- plot(fit, type = 'score', theta_lim = c(-6, 6), main = "")

#-3<b<3
#.5<a<2; baker p12
```

```{r item-categorization, include =F}
very.low <- sum(IRT.details$a >=.10 & IRT.details$a<.34, na.rm=TRUE)
low <- sum(IRT.details$a >=.34 & IRT.details$a<.64, na.rm=TRUE)
moderate <- sum(IRT.details$a >=.64 & IRT.details$a<1.34, na.rm=TRUE)
high <- sum(IRT.details$a >=1.34 & IRT.details$a<1.69, na.rm=TRUE)
very.high <- sum(IRT.details$a >=1.69, na.rm=TRUE)

```

We fitted BCS to the IRT framework using "graded response" model [@samejima1969estimation] to the combined sample of study 1 and study 2 (n= `r nrow(irt.data)`). It required 20 iterations (Log-likelihood -12974.970) for the  model to converge. For the fitted model, Among the `r nrow(items)` retained items the mean item discrimination was `r apa(mean(items$a),2,T)`± `r apa(sd(items$a),2,T)` (range = `r apa(min(items$a),2,T)`-`r apa(max(items$a),2,T)`).  Table \@ref(tab:irttab) summarizes the item discrimination, item difficulty and item fit statistics of the revised models. All items has a moderate discrimination. Standardized outfit statistics ranged between `r apa(min(item.fit$z.outfit),2,T)`-`r apa(max(item.fit$z.outfit),2,T)` indicating a sufficient item fit to the models [@desjardinsHandbookEducationalMeasurement2018]. Sufficent item fit is also reflected by the RMSEA values associated with S-$\chi^2$ statistics ( `r apa(min(item.fit$RMSEA.S_X2),2,T)`-`r apa(max(item.fit$RMSEA.S_X2),2,T)`). Lastly, Fig\@ref(fig:person-fit) indicates that for the Zh is larger than -2 for most participants, suggesting a good person-fit.

```{r person-fit, fig.cap="Person Fit"}
knitr::include_graphics('Figures/tiff/person.tiff')

```

```{r irttab, results='asis'}
papaja::apa_table(IRT.details, caption = "Items discrimination and response category difficulty thresholds of 17 items in  Bangla Communication Scale (n =581)", note = "a = item discrimination parameter; b(1-4) = response category difficulty parameter")
```

```{r OCC, include=F}
ggicc <- function(model, item, theta){
  Theta <- matrix(seq(-theta,theta, by = .1))
  iteminfo <- mirt::extract.item(model, item)
  P <-mirt::probtrace(x=iteminfo , Theta=Theta  )
  icc <- data.frame(P = P, Theta = Theta)
  colnames(icc) <- c(paste("P", 1:ncol(P), sep=''), "Theta")
  icc2<- reshape(icc, direction='long', varying = paste("P", 1:ncol(P), sep=''), v.names = 'P',
                 times = paste("P", 1:ncol(P), sep=''))
  plot <- ggplot2::ggplot(icc2,aes(Theta,P, col =time))+geom_line()+xlab(expression(theta)) + 
    ylab(expression(P(theta)))+ theme(legend.title=element_blank())
  return(plot)
  
}

library(ggsci)

item03 <- ggicc(fit,1,6)+apatheme+ggtitle("item03")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item04 <- ggicc(fit,2,6)+apatheme+ggtitle("item04")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))



item06 <- ggicc(fit,3,6)+apatheme+ggtitle("item06")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item07 <- ggicc(fit,4,6)+apatheme+ggtitle("item07")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item08 <- ggicc(fit,5,6)+apatheme+ggtitle("item08")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))




item10 <- ggicc(fit,6,6)+apatheme+ggtitle("item10")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item11 <- ggicc(fit,7,6)+apatheme+ggtitle("item11")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))
ggsave("Figures/600/ideal_icc.png",item11 , width = 12, height = 8, dpi = 600, bg = "white")


item12 <- ggicc(fit,8,6)+apatheme+ggtitle("item12")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item13 <- ggicc(fit,9,6)+apatheme+ggtitle("item013")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item14 <- ggicc(fit,10,6)+apatheme+ggtitle("item14")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item15 <- ggicc(fit,11,6)+apatheme+ggtitle("item15")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))



item17 <- ggicc(fit,12,6)+apatheme+ggtitle("item17")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item18 <- ggicc(fit,13,6)+apatheme+ggtitle("item18")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item19 <- ggicc(fit,14,6)+apatheme+ggtitle("item19")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item20 <- ggicc(fit,15,6)+apatheme+ggtitle("item20")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))


item21 <- ggicc(fit,16,6)+apatheme+ggtitle("item21")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))

item22 <- ggicc(fit,17,6)+apatheme+ggtitle("item22")+apatheme+scale_color_npg()+
  scale_y_continuous(breaks=c(0,.5,1), limits = c(0, 1))



ICC <- cowplot::plot_grid(item03, item04, item06, item07, item08, 
                   item10, item11, item12, item13, item14, item15,  item17, item18, item19,
                   item20, item21, item22,
                      labels = "AUTO",
                     ncol=3,  
                    label_size = 15, 
                     align = "v")


ggsave("Figures/600/ICC.png",ICC , width = 7, height =7, dpi = 600, bg = "white")

ggsave("Figures/tiff/ICC.tiff",ICC , width = 7, height =7, dpi = 600, bg = "white")


```

```{r figICC, eval=FALSE, fig.cap="Option Charecteritics Curve.", warning=FALSE, include=FALSE, out.height='100%'}

knitr::include_graphics("Figures/tiff/ICC.tiff", dpi =600)


```

```{r Test-info, include =F}


# iteminfo <- plot(fit, type = "infotrace",which.item =2)
# 
# itemplot.01 <- tabledown::ggiteminfo(fit,1,6)+apatheme+
#   ggtitle(" Item03")+theme(legend.position = "none")+
#   labs(y = "Item Information")+
#   scale_color_npg()+geom_hline(yintercept = .20, colour ="red")+geom_area(fill ="palegreen4" )+
#   xlab(expression(theta))+ ylab(expression(I(theta)))
# 
# 
# itemplot.02 <- tabledown::ggiteminfo(fit,2,6)+apatheme+
#   ggtitle(" Item04")+theme(legend.position = "none")+
#   labs(y = "Item Information")+
#   scale_color_npg()+geom_hline(yintercept = .20, colour ="red")+geom_area(fill ="palegreen4" )+
#   xlab(expression(theta))+ ylab(expression(I(theta)))
# 
# 
# 

# good.info <- cowplot::plot_grid( item6.iic1, item7.iic1, item11.iic1, item12.iic1, item14.iic1, item15.iic1 , item18.iic1, item19.iic1, item20.iic1, item21.iic1, item22.iic1, 
#                                  labels = "AUTO",ncol=3, label_size = 15,align = "v")
# 
# 
# ggsave("Figures/good.info.png",good.info, width = 12, height = 8, dpi = 600, bg = "white")

test.info <- tabledown::ggtestinfo(irt.data.1, fit)+ apatheme+geom_line(colour = "black", size=1.5)+geom_area(fill ="#E64B3599" )
# +geom_vline(xintercept = -3, colour ="black")+
#   geom_vline(xintercept = .5, colour ="black")
ggsave("Figures/600/TIC.png",test.info , width = 3.5, height = 3.5, dpi = 600, bg = "white")

ggsave("Figures/tiff/TIC.tiff",test.info , width = 3.5, height = 3.5, dpi = 600, bg = "white")

library(plotly)
info.p <- plotly::ggplotly(test.info)



```

```{r estimation, include=F}
estimation <- as.vector(fscores(fit, method = "EAP",
                                           full.scores = TRUE, 
                                           full.scores.SE = F))

```

```{r WPdata, warning=F, include=FALSE}

library(RColorBrewer)
estimation <- as.data.frame(estimation)

threshold <- items[,2:5]

itemlevelcolors <- matrix(rep(brewer.pal(4, "Set1"), 17), byrow = TRUE, ncol = 4)


```

```{r saveWrightmao,  warning=F, message=F}
tiff("Figures/tiff/personmap.tiff", width = 7, height = 7,units="in", res= 600, pointsize = 12 )
library(WrightMap)
WrightMap::wrightMap(estimation, threshold , 
          item.prop = 0.65,
          main.title = "Person-Map",
          # dim.names = c("Victimization", "Aggression"),
          thr.sym.col.fg = itemlevelcolors,
          thr.sym.col.bg = itemlevelcolors,
          vertLines = TRUE,
          show.thr.lab = F,
          dim.color = brewer.pal(5, "Set3"),
          label.items.srt = 45,
          cex = 1.5,
          return.thresholds=F
          )
```

```{r WP, eval=FALSE, fig.cap="Person Item Map", warning=FALSE, include=FALSE}

knitr::include_graphics('Figures/tiff/personmap.tiff')

```

```{r IIC-code, include =F}

pacman::p_load(reshape,ggsci)
Theta <- matrix(seq(-6,6, by = .1))

##Item Extraction
item03 <- extract.item(fit, 1)#item number
item04 <- extract.item(fit, 2)
item06 <- extract.item(fit, 3)
item07 <- extract.item(fit, 4)
item08 <- extract.item(fit, 5)
item10 <- extract.item(fit,6)
item11<- extract.item(fit, 7)
item12 <-extract.item(fit, 8)
item13 <- extract.item(fit, 9)
item14 <- extract.item(fit, 10)
item15 <- extract.item(fit, 11)
item17 <- extract.item(fit, 12)
item18 <- extract.item(fit, 13)
item19 <- extract.item(fit, 14)
item20 <- extract.item(fit, 15)
item21 <- extract.item(fit, 16)
item22 <- extract.item(fit, 17)



##Item Info
Item03 <- iteminfo(item03, Theta)
Item04 <- iteminfo(item04, Theta)
Item06 <- iteminfo(item06, Theta)
Item07 <- iteminfo(item07, Theta)
Item08 <- iteminfo(item08, Theta)
Item10 <- iteminfo(item10, Theta)
Item11 <- iteminfo(item11, Theta)
Item12 <- iteminfo(item12, Theta)
Item13 <- iteminfo(item13, Theta)
Item14 <- iteminfo(item14, Theta)
Item15 <- iteminfo(item15, Theta)
Item17 <- iteminfo(item17, Theta)
Item18<- iteminfo(item18, Theta)
Item19 <- iteminfo(item19, Theta)
Item20 <- iteminfo(item20, Theta)
Item21 <- iteminfo(item21, Theta)
Item22 <- iteminfo(item22, Theta)


#Data frame

item.info.data <- as.data.frame(cbind(Item03, Item04,Item06, Item07, Item08,
                                      Item10, Item11, Item12, Item13, Item14,
                                      Item15, Item17, Item18, Item19, Item20,
                                      Item21, Item22))



item.info.data.long <- melt(item.info.data)




item.info.data.2 <- data.frame(Theta=seq(-6,6, by = .1), item.info.data.long)


pacman::p_load(ggsci)

item.info.plot <- ggplot(item.info.data.2,aes(Theta,value,col=variable))+geom_line()+apatheme+
  ggtitle("Item Information Plot")+theme(legend.position = "none")+
  facet_wrap(~variable)+theme(strip.text.x = element_text(size = 15))+geom_area()+ scale_color_npg()+aes(fill = as.factor(variable))+xlab(expression(theta)) + 
  ylab(expression(I(theta)))

# facet_wrap(~variable,scales = "free")++geom_hline(yintercept = .20, colour ="red")

ggsave("Figures/600/itemInfoplot.png",item.info.plot, width = 7, height =7, dpi = 600, bg ="white")

ggsave("Figures/tiff/itemInfoplot.tiff",item.info.plot, width = 7, height =7, dpi = 600, bg ="white")




```

```{r conrel-print, include=F}
##
tiff(filename="Figures/tiff/conrel.tiff", 
    type="cairo",
    units="in", 
    width=3.5, 
    height=3.5, 
    pointsize=12, 
    res=600)
library(latticeExtra)
library(directlabels)
font.settings <- list(
  font = 1,
  cex = 6,
  fontfamily = "sans")

apa.latice  <- list(
  par.xlab.text = font.settings,
  par.ylab.text = font.settings,
  axis.text = font.settings,
  sub.text = font.settings,
  add.text = font.settings)


 plot(fit, type = 'rxx', theta_lim = c(-6, 6), 
      main="", par.settings=c(apa.latice),col.line = "#E69F00",lwd = 3.5 )


dev.off()
```

Item information curve (IIC) and test information curve (TIC) indicate the amount of information an item and the full scale carry along the latent trait continuum, respectively (Figure\@ref(fig:figICC) & Figure\@ref(fig:figTIC) ). Examination of the IICs' revealed that items  04 11, 15 and  21 carried comparatively higher information than other items.    Test information curves (TIC) for fitted models (Fig \@ref(fig:figTIC)) indicated that the scale substantial information across the theta continuum indicating its ability to provide information on a good range of latent ability. Also the change of the information across the theta continuum for was steady. We conferred the ability was estimated with precision near the peak information area [@RN1275] in the  $\theta$ range  = -3 and $\theta$ = 2, which is sufficient to discriminate. Conditional reliability plots (Fig \@ref(fig:figconrel)) also indicated the scale  was most reliably estimating scores between -4 to 3 $\theta$ range. The marginal reliability estimates the scale was  `r round(marginal.rel,2)`.

```{r figIIC, fig.cap = "Item Information Curve.",  out.height='100%',out.width='100%', warning=FALSE}

knitr::include_graphics("Figures/tiff/itemInfoplot.tiff", dpi =600)

```

```{r figTIC, fig.cap = "TIC.",  out.height='100%', warning=FALSE}
knitr::include_graphics("Figures/tiff/TIC.tiff", dpi =600)

```

```{r figconrel, fig.cap = "Conditional Reliability.", out.width= '100%', out.height='50%', warning=FALSE}

knitr::include_graphics("Figures/tiff/conrel.tiff", dpi =600)


```

```{r dif, eval=FALSE, include=FALSE}
library("lordif")
gender <- as.data.frame(data$Gender)
colnames(gender) <- "Gender"
gender$Gender <- as.factor(gender$Gender)
irt.data <- na.omit(irt.data)
communication <- sem.data[,c(2:24)]
dif.data <- cbind(gender, communication)
dif.data <- na.omit(dif.data)
dif.data.full <- as.data.frame(dif.data)
DIF <- lordif(as.data.frame(irt.data), group = dif.data.full$Gender, criterion = "Chisqr")

DIF$stats[,1:5]
plot(DIF)
```

#### Concurrent validity

```{r validity-data, include =F}

val.data<- validity.data.full %>% 
  dplyr::select( CS03, CS04, CS06, CS07,CS08,CS10,CS11,    CS12, 
                 CS13,CS14,CS15,CS17, CS18, CS19, CS20 ,CS21, CS22) %>% 
  rowwise() %>% 
  mutate(Total_communication = sum(across(starts_with("CS")), na.rm = T),
         F1 = sum(CS15,CS22,CS20,CS14,CS18,CS13,CS06,CS10, CS11),
         F2 = sum(CS19,CS04,CS17,CS08,CS07))


# DAS<- das21.data.full %>% 
#   dplyr::select(CS01:D21) %>% 
#   rowwise() %>% 
#   mutate(Communication = sum(CS03, CS04, CS06, CS07,CS08,CS10,CS11,    CS12, 
#                  CS13,CS14,CS15,CS17, CS18, CS19, CS20 ,CS21, CS22),
#     DAS_Depression = sum(D03, D05, D10,D13, D16, D17, D21),
#          DAS_Anxiety = sum(D02, D04, D07, D09, D15, D19, D20),
#          DAS_Stress = sum (D01, D06, D08, D11, D12, D14, D18))



val.data.2 <- as.data.frame(cbind(val.data$Total_communication,val.data$F1, val.data$F2, validity.data.full$Total_HS, validity.data$Total_LS, validity.data.full$Total_SE))

colnames(val.data.2) <- c("Communication","F1", "F2", "Hopelessness", "Life Satisfaction", "SE")
validity <- na.omit(val.data.2)
```

```{r correlationfunc, include =F}
glrstab<- function(x, export=FALSE) {
 
 r <-corr.test(x)$r	#taking just the correlation matrix; no N, or p
 p <-corr.test(x)$p	#taking the p*s
 
#define notions for significance levels
 mystars <- ifelse(p < .001, "**"
                   , ifelse(p < .01, "**"
                            , ifelse(p < .05, "*"
                                     , ifelse(p < .10, "+", " "))))
 
 #round r, define new matrix Rnew with the correlations from rnd and paste mystars
 rnd  <- papaja::printnum(r, gt1 = FALSE, digits = 2)  #round, drop leading 0 - Thanks CRSH!								                     
 Rnew <- matrix(paste(rnd, mystars, sep=""), ncol=ncol(rnd)) 
 
  #remove 1.0 correlations from diagonal  and set the strings
 diag(Rnew) <- ''		
 Rnew[upper.tri(Rnew)] <- ''								                	
 
 rownames(Rnew) <- paste(1:ncol(rnd), colnames(rnd), sep=" ")         #define number and name
 colnames(Rnew) <- paste(1:ncol(rnd), "", sep="") 			       #define number
 
#fun-part: we trim the top half 
 Rnew[upper.tri(Rnew)] <- ''			
 Rnew
 
 #Rnew <- cbind(round(describe(x)[,3:4],2), Rnew)		     #describe x, M sD - put them in the matrix
 #colnames(Rnew)[1:2] <- c("M","SD")					      		#Beschriftung der neuen Spalten
 Rnew <- Rnew[,1:(ncol(Rnew)-1)]							        	#delete the last column (ugly)
 
 #export to clipboard
 
   if (export==TRUE){
   result<-write.table(Rnew
                       , "clipboard"
                       , sep=";"
                       , row.names=FALSE)
 }
 else result <- Rnew
 return(result)
 
}

```

```{r correlations, include =F}
Cor <-glrstab(validity) #the function in action!

cor.tab <- as_tibble(cor(validity))

```

```{r tabvalidity, eval=FALSE, include=FALSE, results='asis'}
papaja::apa_table(Cor, escape  = FALSE
                , caption = "Correlation matrix of the main variables"
                , note    = "**p < .001")
```

Bangla Communication Scale significantly negatively correlated with hopelessness, r = .-16, p<0.01. Such a significant negative correlation was also reported in -----.

# General Discussion

## Ethical Consideration 

All procedures performed in studies involving human participants were in accordance with the 1964 Helsinki declaration and its later amendments or comparable ethical standards. This article does not contain any studies with animals performed by any of the authors.

## Data and code availability
All code and data underlying this article is available on a public GitHub repository (https://github.com/masiraji/Communication).

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
